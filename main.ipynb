{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jayson3xxx\\AppData\\Local\\Temp\\ipykernel_22896\\3620069876.py:3: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel, BayesianOptimization\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kerastuner import HyperModel, BayesianOptimization\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "import kerastuner as kt\n",
    "\n",
    "import kagglehub\n",
    "import pandasql\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit,train_test_split\n",
    "from category_encoders import TargetEncoder , HelmertEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeDf = pd.read_csv(\"stores.csv\")\n",
    "holydaysEventsDf = pd.read_csv(\"holidays_events.csv\")\n",
    "oilDf = pd.read_csv(\"oil.csv\")\n",
    "transactionsDf = pd.read_csv('transactions.csv')\n",
    "trainDf = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>type_x</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>transferred</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>transactions</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_y</th>\n",
       "      <th>cluster</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>97.01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>97.01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>97.01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>97.01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2013-02-11</td>\n",
       "      <td>97.01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>396</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  dcoilwtico   type_x    locale locale_name  transferred  \\\n",
       "33 2013-02-11       97.01  Holiday  National     Ecuador        False   \n",
       "34 2013-02-11       97.01  Holiday  National     Ecuador        False   \n",
       "35 2013-02-11       97.01  Holiday  National     Ecuador        False   \n",
       "36 2013-02-11       97.01  Holiday  National     Ecuador        False   \n",
       "37 2013-02-11       97.01  Holiday  National     Ecuador        False   \n",
       "\n",
       "    store_nbr  transactions   city      state type_y  cluster      family  \\\n",
       "33          1           396  Quito  Pichincha      D       13  AUTOMOTIVE   \n",
       "34          1           396  Quito  Pichincha      D       13   BABY CARE   \n",
       "35          1           396  Quito  Pichincha      D       13      BEAUTY   \n",
       "36          1           396  Quito  Pichincha      D       13   BEVERAGES   \n",
       "37          1           396  Quito  Pichincha      D       13       BOOKS   \n",
       "\n",
       "    onpromotion  sales  \n",
       "33            0    0.0  \n",
       "34            0    0.0  \n",
       "35            0    0.0  \n",
       "36            0  172.0  \n",
       "37            0    0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TotalDf = pd.merge(oilDf,holydaysEventsDf,on=['date'])\n",
    "TotalDf = pd.merge(TotalDf,transactionsDf,on=['date'])\n",
    "TotalDf = pd.merge(TotalDf,storeDf, on=['store_nbr'])\n",
    "TotalDf = pd.merge(TotalDf,trainDf, on=['date','store_nbr'])\n",
    "TotalDf.dropna(inplace=True)\n",
    "TotalDf.drop(columns=['id' , 'description'] , inplace=True)\n",
    "TotalDf['sales'] = TotalDf.pop('sales')\n",
    "TotalDf['date'] = pd.to_datetime(TotalDf['date'])\n",
    "TotalDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TotalDf.drop(['date'], axis=1)\n",
    "\n",
    "# Кодирование категориальных признаков (если они есть)\n",
    "data = pd.get_dummies(data, columns=['type_x', 'locale', 'locale_name', 'city', 'state', 'type_y', 'family'], drop_first=True)\n",
    "\n",
    "# Нормализация данных\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "# Создание последовательностей временных данных с дополнительными признаками\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:(i + seq_length)])  # Все столбцы, включая дополнительные признаки\n",
    "        y.append(data[i + seq_length, -1])  # Целевая переменная 'sales'\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "SEQ_LENGTH = 7  # Используем 7 дней для прогноза\n",
    "X, y = create_sequences(scaled_data, SEQ_LENGTH)\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# encoder = HelmertEncoder()\n",
    "# df_encoded = encoder.fit_transform(TotalDf[['type_x', 'locale', 'locale_name', 'city', 'state', 'type_y', 'family']], TotalDf['sales'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 06m 43s]\n",
      "val_loss: 1.774892098183045e-05\n",
      "\n",
      "Best val_loss So Far: 1.1755855666706339e-07\n",
      "Total elapsed time: 02h 33m 20s\n",
      "\n",
      "Лучшие гиперпараметры:\n",
      "- Количество слоев: 1\n",
      "- Количество нейронов: [192]\n",
      "- Активация: tanh\n",
      "- Оптимизатор: adam\n",
      "- Скорость обучения: 0.00036448699004144517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Выбор количества слоев LSTM\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(LSTM(\n",
    "            units=hp.Int(f'units_{i}', min_value=32, max_value=256, step=32),\n",
    "            activation=hp.Choice('activation', ['relu', 'tanh']),\n",
    "            return_sequences=True if i < hp.get('num_layers')-1 else False,\n",
    "            input_shape=(X_train.shape[1], X_train.shape[2])\n",
    "        ))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Выбор оптимизатора и скорости обучения\n",
    "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
    "    lr = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=lr)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=lr)\n",
    "    else:\n",
    "        opt = RMSprop(learning_rate=lr)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Настройка поиска гиперпараметров\n",
    "tuner = BayesianOptimization(\n",
    "    model_builder,\n",
    "    objective='val_loss',\n",
    "    max_trials=15,\n",
    "    executions_per_trial=2,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='sales_forecast'\n",
    ")\n",
    "\n",
    "# Запуск поиска\n",
    "tuner.search(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=32,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)]\n",
    ")\n",
    "\n",
    "# Вывод лучших параметров\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "Лучшие гиперпараметры:\n",
    "- Количество слоев: {best_hps.get('num_layers')}\n",
    "- Количество нейронов: {[best_hps.get(f'units_{i}') for i in range(best_hps.get('num_layers'))]}\n",
    "- Активация: {best_hps.get('activation')}\n",
    "- Оптимизатор: {best_hps.get('optimizer')}\n",
    "- Скорость обучения: {best_hps.get('learning_rate')}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jayson3xxx\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\jayson3xxx\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 12 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]\n",
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "0.00027098460200560096\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import root_mean_squared_error as RMSE\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print(RMSE(y_test , prediction))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
